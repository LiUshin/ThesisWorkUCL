2022-08-16 12:37:28,665 INFO     ---------------------------------------------------------------------------------------------
2022-08-16 12:37:28,665 INFO     Geo: cqd
2022-08-16 12:37:28,665 INFO     Data Path: data/FB15k-237-betae
2022-08-16 12:37:28,665 INFO     #entity: 14505
2022-08-16 12:37:28,665 INFO     #relation: 474
2022-08-16 12:37:28,665 INFO     #max steps: 150000
2022-08-16 12:37:28,665 INFO     Evaluate unoins using: DNF
2022-08-16 12:37:28,665 INFO     loading data
2022-08-16 12:38:11,622 INFO     Training info:
2022-08-16 12:38:11,629 INFO     pni: 14968
2022-08-16 12:38:11,740 INFO     Validation info:
2022-08-16 12:38:11,741 INFO     pni: 5000
2022-08-16 12:38:11,742 INFO     Test info:
2022-08-16 12:38:11,743 INFO     pni: 5000
2022-08-16 12:38:21,876 INFO     Model Parameter Configuration:
2022-08-16 12:38:21,876 INFO     Parameter embeddings.0.weight: torch.Size([14505, 2000]), require_grad = True
2022-08-16 12:38:21,877 INFO     Parameter embeddings.1.weight: torch.Size([474, 2000]), require_grad = True
2022-08-16 12:38:21,877 INFO     Parameter score_transform_fun.weight: torch.Size([2, 2000]), require_grad = True
2022-08-16 12:38:21,877 INFO     Parameter score_transform_fun.bias: torch.Size([2]), require_grad = True
2022-08-16 12:38:21,877 INFO     Parameter t_norm.p: torch.Size([]), require_grad = True
2022-08-16 12:38:21,877 INFO     Parameter Number: 29962003
2022-08-16 12:38:21,916 INFO     Loading checkpoint models/fb15k-237-betae...
2022-08-16 12:38:23,787 INFO     tasks = pni
2022-08-16 12:38:23,788 INFO     init_step = 99999
2022-08-16 12:38:23,788 INFO     Start Training...
2022-08-16 12:38:23,788 INFO     learning_rate = 0
2022-08-16 12:38:23,788 INFO     batch_size = 1024
2022-08-16 12:38:23,788 INFO     hidden_dim = 1000
2022-08-16 12:38:23,788 INFO     gamma = 12.000000
posix.uname_result(sysname='Linux', nodename='sweetums-609-6.local', release='3.10.0-1160.49.1.el7.x86_64', version='#1 SMP Tue Nov 30 15:51:32 UTC 2021', machine='x86_64')
Traceback (most recent call last):
  File "main.py", line 632, in <module>
    main(parse_args())
  File "main.py", line 543, in main
    log = KGReasoning.train_step(model, optimizer, train_other_iterator, args, step)
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/models.py", line 674, in train_step
    model.forward(positive_sample=positive_sample,
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/base.py", line 503, in forward
    scores = d2.query_pni(entity_embeddings=self.embeddings[0],
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/discrete.py", line 459, in query_pni
    scores_1 = query_2pn(entity_embeddings=entity_embeddings, predicate_embeddings=predicate_embeddings,
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/discrete.py", line 497, in query_2pn
    atom2_scores_2d, _ = score_candidates(s_emb=x1_k_emb_2d, p_emb=p2_emb,
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/discrete.py", line 33, in score_candidates
    atom_scores_2d = scoring_function(s_emb, p_emb, candidates_emb)
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/base.py", line 586, in scoring_function
    res, _ = self.score_o(lhs_, rel_, rhs_)
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/base.py", line 249, in score_o
    score_1 = (lhs[0] * rel[0] - lhs[1] * rel[1]) @ rhs[0].transpose(-1, -2)
RuntimeError: CUDA out of memory. Tried to allocate 7.08 GiB (GPU 0; 10.76 GiB total capacity; 3.02 GiB already allocated; 6.70 GiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
