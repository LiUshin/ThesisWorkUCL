2022-07-31 11:35:33,495 INFO     ---------------------------------------------------------------------------------------------
2022-07-31 11:35:33,495 INFO     Geo: cqd
2022-07-31 11:35:33,495 INFO     Data Path: data/FB15k-237-betae
2022-07-31 11:35:33,495 INFO     #entity: 14505
2022-07-31 11:35:33,495 INFO     #relation: 474
2022-07-31 11:35:33,495 INFO     #max steps: 150000
2022-07-31 11:35:33,495 INFO     Evaluate unoins using: DNF
2022-07-31 11:35:33,495 INFO     loading data
2022-07-31 11:36:05,425 INFO     Training info:
2022-07-31 11:36:05,428 INFO     2p: 149689
2022-07-31 11:36:07,323 INFO     Validation info:
2022-07-31 11:36:07,323 INFO     2p: 5000
2022-07-31 11:36:07,325 INFO     Test info:
2022-07-31 11:36:07,325 INFO     2p: 5000
2022-07-31 11:36:09,601 INFO     Model Parameter Configuration:
2022-07-31 11:36:09,602 INFO     Parameter embeddings.0.weight: torch.Size([14505, 2000]), require_grad = True
2022-07-31 11:36:09,602 INFO     Parameter embeddings.1.weight: torch.Size([474, 2000]), require_grad = True
2022-07-31 11:36:09,602 INFO     Parameter Number: 29958000
2022-07-31 11:36:09,621 INFO     Loading checkpoint models/fb15k-237-betae...
2022-07-31 11:36:10,066 INFO     tasks = 2p
2022-07-31 11:36:10,066 INFO     init_step = 99999
2022-07-31 11:36:10,066 INFO     Start Training...
2022-07-31 11:36:10,066 INFO     learning_rate = 0
2022-07-31 11:36:10,066 INFO     batch_size = 1024
2022-07-31 11:36:10,066 INFO     hidden_dim = 1000
2022-07-31 11:36:10,066 INFO     gamma = 12.000000
posix.uname_result(sysname='Linux', nodename='gonzo-605-2.local', release='3.10.0-1160.66.1.el7.x86_64', version='#1 SMP Wed May 18 16:02:34 UTC 2022', machine='x86_64')
Traceback (most recent call last):
  File "main.py", line 632, in <module>
    main(parse_args())
  File "main.py", line 537, in main
    log = KGReasoning.train_step(model, optimizer, train_path_iterator, args, step)
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/models.py", line 674, in train_step
    model.forward(positive_sample=positive_sample,
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/base.py", line 439, in forward
    scores = d2.query_2p(entity_embeddings=self.embeddings[0],
  File "/home/shinaliu/KG/models/kg-reasoning-alpha/cqd/discrete.py", line 103, in query_2p
    res = t_norm(atom1_scores_3d, atom2_scores_3d)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torchnorms/tnorms/classic.py", line 63, in __call__
    return (a * b) / (1.0 + (1.0 - a) * (1.0 - b))
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/_tensor.py", line 31, in wrapped
    return f(*args, **kwargs)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/_tensor.py", line 604, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
RuntimeError: CUDA out of memory. Tried to allocate 1.77 GiB (GPU 0; 11.91 GiB total capacity; 10.21 GiB already allocated; 1014.94 MiB free; 10.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
