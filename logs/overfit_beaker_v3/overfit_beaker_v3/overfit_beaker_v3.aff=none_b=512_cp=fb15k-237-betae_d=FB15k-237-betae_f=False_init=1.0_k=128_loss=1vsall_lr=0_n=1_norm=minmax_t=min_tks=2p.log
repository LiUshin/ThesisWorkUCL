2022-07-28 10:52:46,181 INFO     ---------------------------------------------------------------------------------------------
2022-07-28 10:52:46,181 INFO     Geo: cqd
2022-07-28 10:52:46,181 INFO     Data Path: data/FB15k-237-betae
2022-07-28 10:52:46,181 INFO     #entity: 14505
2022-07-28 10:52:46,181 INFO     #relation: 474
2022-07-28 10:52:46,181 INFO     #max steps: 150000
2022-07-28 10:52:46,181 INFO     Evaluate unoins using: DNF
2022-07-28 10:52:46,181 INFO     loading data
2022-07-28 10:53:24,952 INFO     Training info:
2022-07-28 10:53:24,956 INFO     2p: 149689
2022-07-28 10:53:27,104 INFO     Validation info:
2022-07-28 10:53:27,105 INFO     2p: 5000
2022-07-28 10:53:27,106 INFO     Test info:
2022-07-28 10:53:27,107 INFO     2p: 5000
2022-07-28 10:53:31,063 INFO     Model Parameter Configuration:
2022-07-28 10:53:31,063 INFO     Parameter embeddings.0.weight: torch.Size([14505, 2000]), require_grad = True
2022-07-28 10:53:31,064 INFO     Parameter embeddings.1.weight: torch.Size([474, 2000]), require_grad = True
2022-07-28 10:53:31,064 INFO     Parameter Number: 29958000
posix.uname_result(sysname='Linux', nodename='sweetums-609-7.local', release='3.10.0-1160.66.1.el7.x86_64', version='#1 SMP Wed May 18 16:02:34 UTC 2022', machine='x86_64')
Traceback (most recent call last):
  File "main.py", line 632, in <module>
    main(parse_args())
  File "main.py", line 486, in main
    model = model.cuda()
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 688, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 688, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
