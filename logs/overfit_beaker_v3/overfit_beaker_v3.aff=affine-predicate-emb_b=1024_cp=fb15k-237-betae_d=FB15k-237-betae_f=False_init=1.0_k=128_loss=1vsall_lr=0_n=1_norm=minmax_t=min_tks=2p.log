2022-07-28 10:52:23,271 INFO     ---------------------------------------------------------------------------------------------
2022-07-28 10:52:23,272 INFO     Geo: cqd
2022-07-28 10:52:23,272 INFO     Data Path: data/FB15k-237-betae
2022-07-28 10:52:23,272 INFO     #entity: 14505
2022-07-28 10:52:23,272 INFO     #relation: 474
2022-07-28 10:52:23,272 INFO     #max steps: 150000
2022-07-28 10:52:23,272 INFO     Evaluate unoins using: DNF
2022-07-28 10:52:23,272 INFO     loading data
2022-07-28 10:52:53,357 INFO     Training info:
2022-07-28 10:52:53,872 INFO     2p: 149689
2022-07-28 10:52:55,567 INFO     Validation info:
2022-07-28 10:52:55,567 INFO     2p: 5000
2022-07-28 10:52:55,569 INFO     Test info:
2022-07-28 10:52:55,569 INFO     2p: 5000
/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/cuda/__init__.py:145: UserWarning: 
NVIDIA A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
If you want to use the NVIDIA A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
2022-07-28 10:52:55,930 INFO     Model Parameter Configuration:
2022-07-28 10:52:55,930 INFO     Parameter embeddings.0.weight: torch.Size([14505, 2000]), require_grad = True
2022-07-28 10:52:55,930 INFO     Parameter embeddings.1.weight: torch.Size([474, 2000]), require_grad = True
2022-07-28 10:52:55,930 INFO     Parameter score_transform_fun.weight: torch.Size([2, 2000]), require_grad = True
2022-07-28 10:52:55,930 INFO     Parameter score_transform_fun.bias: torch.Size([2]), require_grad = True
2022-07-28 10:52:55,930 INFO     Parameter Number: 29962002
posix.uname_result(sysname='Linux', nodename='bert.local', release='3.10.0-1160.49.1.el7.x86_64', version='#1 SMP Tue Nov 30 15:51:32 UTC 2021', machine='x86_64')
Traceback (most recent call last):
  File "main.py", line 632, in <module>
    main(parse_args())
  File "main.py", line 486, in main
    model = model.cuda()
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 688, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/shinaliu/miniconda3/envs/kg/lib/python3.8/site-packages/torch/nn/modules/module.py", line 688, in <lambda>
    return self._apply(lambda t: t.cuda(device))
RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
